# Humanâ€“Robot Trust Dynamics + Human Preferenceâ€“Aware Risk Navigation

This module extends the dynamic navigation system by coupling:

1ï¸âƒ£ **Robot Self-Trust**  
2ï¸âƒ£ **Human Trust in the Robot**  
3ï¸âƒ£ **Human Preference Awareness**

into a unified **risk-aware navigation policy controller**.  
The system allows the robot to update its behavior based on experience (success, failure, human override, approval) *and* adaptively follow human comfort preferences.

---

## âœ¨ Concept Overview

### ğŸ”¹ Baseline Navigation
The system already supports riskâ€“aware navigation using:

- self-trust
- OOD awareness
- drift awareness
- calibrated uncertainty

with a classical cost model:

\[
\text{Cost} = L(\pi) + \lambda \cdot R(\pi)
\]

where Î» controls how aggressively or conservatively the robot navigates.

---

## ğŸ”¥ Human Preference Layer
Humans express preferences like:

- â€œPrefer safer route even if slowerâ€
- â€œReach fast, I accept riskâ€
- â€œAvoid dark / low-feature regionsâ€
- â€œBalancedâ€

These are parsed into:

- continuous risk preference h âˆˆ [0,1]
- semantic constraints:
  - avoid_dark_areas
  - avoid_low_feature_areas
  - prefer_well_mapped

The preference modifies Î» using a human influence factor:

\[
\lambda_{\text{effective}} =
f(\lambda_\text{robot}, h, \alpha_\text{human})
\]

---

## ğŸ¤ Humanâ€“Robot Trust Dynamics

We introduce **Trust Dynamics**, meaning both sides â€œlearn each otherâ€:

### âœ… Robot Self-Trust
Increases when:
- navigation succeeds
Decreases when:
- near-miss
- failure
- human override

### âœ… Human Trust in Robot
Estimated internally by the robot.
Increases with:
- success
- human approval
Decreases with:
- failures
- overrides
- unsafe behavior

Trust is normalized in \[0,1\].

---

## ğŸ§  Trust â†’ Policy Mapping

### Î» Robot (Risk Weight)
- Low self_trust â†’ **increase Î»** (safer)
- High self_trust â†’ **reduce Î»** (more aggressive)

### Human Influence Scale
- High human_trust â†’ **preferences weigh more**
- Low human_trust â†’ **preferences weigh less**

### Safe Mode
Enabled when:
- robot self-trust is too low
- estimated human trust is too low

---

## ğŸ§ª Demo Scripts

### 1ï¸âƒ£ Trust Dynamics Only

```bash
python3 run_trust_dynamics_demo.py


# Humanâ€“Robot Trust Dynamics + Human Preferenceâ€“Aware Risk Navigation

This module extends the dynamic navigation system by coupling:

1ï¸âƒ£ **Robot Self-Trust**  
2ï¸âƒ£ **Human Trust in the Robot**  
3ï¸âƒ£ **Human Preference Awareness**

into a unified **risk-aware navigation policy controller**.  
The system allows the robot to update its behavior based on experience (success, failure, human override, approval) *and* adaptively follow human comfort preferences.

---

## âœ¨ Concept Overview

### ğŸ”¹ Baseline Navigation
The system already supports riskâ€“aware navigation using:

- self-trust
- OOD awareness
- drift awareness
- calibrated uncertainty

with a classical cost model:

\[
\text{Cost} = L(\pi) + \lambda \cdot R(\pi)
\]

where Î» controls how aggressively or conservatively the robot navigates.

---

## ğŸ”¥ Human Preference Layer
Humans express preferences like:

- â€œPrefer safer route even if slowerâ€
- â€œReach fast, I accept riskâ€
- â€œAvoid dark / low-feature regionsâ€
- â€œBalancedâ€

These are parsed into:

- continuous risk preference h âˆˆ [0,1]
- semantic constraints:
  - avoid_dark_areas
  - avoid_low_feature_areas
  - prefer_well_mapped

The preference modifies Î» using a human influence factor:

\[
\lambda_{\text{effective}} =
f(\lambda_\text{robot}, h, \alpha_\text{human})
\]

---

## ğŸ¤ Humanâ€“Robot Trust Dynamics

We introduce **Trust Dynamics**, meaning both sides â€œlearn each otherâ€:

### âœ… Robot Self-Trust
Increases when:
- navigation succeeds
Decreases when:
- near-miss
- failure
- human override

### âœ… Human Trust in Robot
Estimated internally by the robot.
Increases with:
- success
- human approval
Decreases with:
- failures
- overrides
- unsafe behavior

Trust is normalized in \[0,1\].

---

## ğŸ§  Trust â†’ Policy Mapping

### Î» Robot (Risk Weight)
- Low self_trust â†’ **increase Î»** (safer)
- High self_trust â†’ **reduce Î»** (more aggressive)

### Human Influence Scale
- High human_trust â†’ **preferences weigh more**
- Low human_trust â†’ **preferences weigh less**

### Safe Mode
Enabled when:
- robot self-trust is too low
- estimated human trust is too low

---

## ğŸ§ª Demo Scripts

### 1ï¸âƒ£ Trust Dynamics Only

```bash
python3 run_trust_dynamics_demo.py


-----
Shows:

self_trust_robot

human_trust_in_robot

Î»_robot

human influence

safe mode flag


2ï¸âƒ£ Trust + Human Preferences Integration

Shows step-by-step:

event (SUCCESS, FAILURE, HUMAN_OVERRIDE, etc.)

human preference text

trust evolution

Î»_robot

human influence scale

human risk preference h

final Î»_effective sent to the planner

This demonstrates how trust and preference co-evolve.

3ï¸âƒ£ Export Results for Plots
python3 save_trust_preference_results.py


Generates:

trust_preference_results.csv


Containing:

step

event

human preference text

robot self-trust

human trust

Î»_robot

Î»_effective

safe mode

Ready for:

Excel

pandas analysis

matplotlib / seaborn plots

research figures

ğŸ¯ Why This Is Important

This framework connects:

Human-centered robotics

Trust modeling

Risk-aware navigation

Explainable robotic decision-making

It enables experiments on:

how humans influence robot risk decisions

how trust changes robot behavior

how failures / successes reshape risk policies

This is currently hot research in:

Humanâ€“Robot Interaction

Trust-Aware Autonomy

Human Preference Integration

ğŸš€ Ready for Extension

Next steps may include:

ROS Integration

Real navigation-based trust adaptation

Trust learning via Bayesian / RL approaches

UI for real user input preferences

Full paper-ready experimental evaluation

âœ”ï¸ Summary

This module delivers:

Human-aware navigation

Trust-evolving autonomy

Adaptive Î»-risk control

Semantic risk constraints

Real experiment logging

It transforms the navigator from a static planner to an adaptive, self-aware, human-aligned system.
python3 run_trust_and_preferences_demo.py

